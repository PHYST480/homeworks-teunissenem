{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 1: Problems\n",
    "### PHYS T480/580, Fall 2018\n",
    "https://github.com/gtrichards/PHYS_T480_F18/\n",
    "\n",
    "\n",
    "## Problem 1\n",
    "\n",
    "Practice your git and github skills by submitting this homework via github:\n",
    "\n",
    "* Clone the class github repository to your computer, the one at https://github.com/gtrichards/PHYS_T480_F18/  (should already have done this).\n",
    "* Click the Github Classroom link you received via the mailing list. This will create a private github repository through which you'll be submitting your homeworks. Clone that repository to your computer.\n",
    "* Copy this notebook from the class github repository to your private homework submission repository. IMPORTANT: rename it to `<filename>-FirstLast.ipynb` once you copy it, where `<filename>` is the existing filename and `FirstLast` are your first and last name. Example: `PHYST480-F18-HW1-GordonRichards.ipynb`.\n",
    "* Solve problems #2, #3, and #4 by filling in the missing cells in the copied notebook.\n",
    "* Commit the notebook to your repository, and `git push` it upstream.\n",
    "\n",
    "\n",
    "## Problem 2\n",
    "Generate a sample of 10,000 data values drawn from N($\\mu$=1.0, $\\sigma$=0.2) and\n",
    "draw a pretty histogram, with the bin size determined using the Freedman-Diaconis\n",
    "rule. Overplot the true distribution. \n",
    "\n",
    "## Problem 3\n",
    "Repeat the problem 2, but now add to the Gaussian sample (concatenate arrays with `np.concatenate()`) \n",
    "another sample of 10,000 data values drawn from a `cauchy` distribution with\n",
    "$\\mu=2.0$ and $\\gamma=0.5$. Do it twice: once with the bin size determined \n",
    "using the Freedman-Diaconis rule and once using the Scott's rule. Comment. \n",
    "\n",
    "\n",
    "## Problem 4\n",
    "Follow the example from the Central Limit Theorem cells in BasicStats2.ipynb and simulate the distribution of 1,000,000 $\\mathscr{N}(0,1)$ draws of $\\chi^2$ for `N=2` and `N=5`.  Overplot the theoretical pdf (it will help to use `scipy.special.gamma()`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some useful definitions and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy import optimize\n",
    "from scipy.stats import cauchy, norm\n",
    "# from astroML.plotting import setup_text_plots\n",
    "# from astroML.stats import sigmaG\n",
    "# from astroML.plotting import hist as fancyhist\n",
    "# setup_text_plots(fontsize=14, usetex=True)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This astroML function adjusts matplotlib settings for a uniform feel in the \n",
    "textbook. Note that with `usetex=True`, fonts are rendered with $\\LaTeX$. This \n",
    "may result in an error if $\\LaTeX$ is not installed on your system.  In that \n",
    "case, you can set usetex to `False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Problem 2\n",
    "# Generate 10000 data values from N(mu=1.0,sigma=0.2)\n",
    "# Draw histogram, bin size determined from Freedman-Diaconis rule\n",
    "# Overplot true distribution\n",
    "\n",
    "#Creating distribution\n",
    "N = 10000\n",
    "mu = 1.0\n",
    "sigma = 0.2\n",
    "normDist = norm(mu,sigma)\n",
    "normData = normDist.rvs(N)\n",
    "trueNormData = normDist.pdf(normData)\n",
    "\n",
    "#Calculating binsize from Freedman-Diaconis Rule\n",
    "q25,q75 = np.percentile(normData,[25,75]) \n",
    "sigmaG = 0.7413*(q75-q25)\n",
    "binsize = 2.7*sigmaG/(N**(1.0/3.0))\n",
    "bins = np.append(np.arange(start=np.min(np.sort(normData)),stop=np.max(np.sort(normData)),step=binsize),np.max(np.sort(normData)))\n",
    "\n",
    "\n",
    "#Plotting distributions\n",
    "plt.hist(normData    ,bins=bins,density=True,histtype=\"step\") #histogram with N draws & bin sized according to Freedman-Diaconis\n",
    "plt.hist(trueNormData,bins=bins,density=True,histtype=\"step\") #histogram of true distribution\n",
    "print()\n",
    "print(\"Binsize:\",str(binsize))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Problem 3\n",
    "# Repeat Problem 2, but add to the guassian sample (concatenate arrays with np.concatenate())\n",
    "#10000 values drawn from cauchy distribution with mu = 2.0 and gamma = 0.5 \n",
    "#Calculate two binsizes, from Freedman-Diaconis and Scott's Rule\n",
    "\n",
    "muTwo = 2.0\n",
    "gamma = 0.5\n",
    "cauchyDist = cauchy(muTwo,gamma)\n",
    "cauchyData = cauchyDist.rvs(N)\n",
    "N = N*2\n",
    "trueCauchyData = cauchyDist.pdf(cauchyData)\n",
    "\n",
    "totalData = np.concatenate((normData,cauchyData))\n",
    "trueTotalData = np.concatenate((trueNormData,trueCauchyData))\n",
    "\n",
    "#Calculating binsize from Freedman-Diaconis Rule\n",
    "q25,q75 = np.percentile(totalData,[25,75]) \n",
    "sigmaG = 0.7413*(q75-q25)\n",
    "binsizeFreedman = (2.7*sigmaG)/(N**(1.0/3.0)) \n",
    "freedmanBins = np.append(np.arange(start=np.min(np.sort(totalData)),stop=np.max(np.sort(totalData)),step=binsizeFreedman),np.max(np.sort(totalData))) \n",
    "\n",
    "#Calculating binsize from Scott's Rule\n",
    "binsizeScott = (3.5*gamma)/(N**(1.0/3.0))\n",
    "scottBins = np.append(np.arange(start=np.min(np.sort(totalData)),stop=np.max(np.sort(totalData)),step=binsizeScott),np.max(np.sort(totalData)))\n",
    "\n",
    "#Plotting distributions\n",
    "plt.hist(totalData,bins=freedmanBins,density = True,histtype=\"step\") #histogram with N draws & bin sized according to Freedman-Diaconis\n",
    "# plt.hist(trueTotalData,bins=freedmanBins,density=True,histtype=\"step\") #histogram of true distribution\n",
    "print()\n",
    "print(\"Freedman-Diaconis Binsize:\",str(binsizeFreedman))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(totalData,bins=scottBins,density=True,histtype=\"step\") #histogram with N draws & bin sized according to Freedman-Diaconis\n",
    "plt.hist(trueTotalData,bins=scottBins,density=True,histtype=\"step\") #histogram of true distribution\n",
    "print()\n",
    "print(\"Scott's Binsize:\",str(binsizeScott))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem 4\n",
    "# Follow the example from the Central Limit Theorem cells in BasicStats2.ipynb \n",
    "# Create a distribution of 1000000 from N(0,1)\n",
    "# Draws of  Ï‡2  for N=2 and N=5\n",
    "# Overplot the theoretical pdf (it will help to use scipy.special.gamma()).\n",
    "\n",
    "\n",
    "# Attempt #1\n",
    "from scipy.stats import chi2\n",
    "\n",
    "N = 1000000\n",
    "mu = 0\n",
    "sigma = 1\n",
    "normDist = norm(mu,sigma)\n",
    "normData = normDist.rvs(N)\n",
    "\n",
    "data2 = chi2(2).rvs(N)\n",
    "data5 = chi2(5).rvs(N)\n",
    "\n",
    "plt.plot(normData,data2)\n",
    "plt.plot(normData,data5)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
